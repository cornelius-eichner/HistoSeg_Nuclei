{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78b3efdc",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "This notebook will preprocess the provided data. This will entail the following steps:\n",
    "\n",
    "Splitting the images in training and validation datasets\n",
    "\n",
    "Calculation of mean and standard deviation across the entire sample for data normalization\n",
    "\n",
    "Loading all data and label data\n",
    "\n",
    "Normalization and standardization of the image data using the computed channel-wise means and standard deviations\n",
    "\n",
    "Saving data as NumPy arrays in training/validation folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f81f9ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Import custom functions\n",
    "from functions import change_img_to_label_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7562d440",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = Path(\"data/tissue_images/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c05965",
   "metadata": {},
   "source": [
    "Loop across all subjects and split between training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37b0afe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 images to Process\n",
      "---\n",
      "22 images for Training\n",
      "6 images for Validation\n"
     ]
    }
   ],
   "source": [
    "all_files = list(root_path.glob(\"*tif\"))  # Get list of all tif file paths in root_path \n",
    "print('{} images to Process'.format(len(all_files)))\n",
    "print('---')\n",
    "val = round(len(all_files) * 0.2)\n",
    "train = len(all_files) - val\n",
    "\n",
    "print('{} images for Training'.format(train))\n",
    "print('{} images for Validation'.format(val))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF8AAAArCAYAAAAe/1QiAAAABHNCSVQICAgIfAhkiAAAA+FJREFUaEPtml1SFDEUhR3UBx8scQX0uIJxBfasQHABCvpqleAGqHEBChuQxg0APmvRbEBHFyDNCuRZy9LzYSIh0003TDdjz+RWnUpyc3OTnNz89MC1a0EmxkBnYj2P13Gk5sCVYxWGRhE7Fb+VPxIy1zjkL89AX00TAcIhNxNWjbtIaero95THPkjNDAwMydue3w2Vk5r7Cu48Bu4a8r8rJY+sCInJh6RhBiCaowfSl4S04f6Ce4cBCIf8Q0P8/ATZ6anvHa9/xrMuTHJcjVHSkedMYAHixnqp5pi7h0eAK2sqMDZ7LP6rm/MM21i8YybH2NkFk5QH6vzAGwC6LwL30hm54StaVmYr7wrPhI/CY2FVINKqCPfEQhVD2QwF+iqSrvG16RiwK2OBHTEibSYf4vcFCISYdwLkLwtbQhWh/b0qhrL5VmIXm/rUsespz850dSVu2lFNNEG8lb4yRHzq6K4yy3iOvQ5fmjFx3scCAdNqYQJEtku8nVCmDAtwfwIzpO/U65cyuxIhPXPptunYWdTg2cZPhEjwo2xVOi41zvDXwoGwkWMnVe3SlUf6BSz8ofBGIFBsMIxcum0in6jpCJztiP96oP69AXaAyfuLdNK4ZomNv1dKCQIIZ+EzYSC8MFByKgzQl54Ui77SKxNV+yU2s1S9rck+FAgAiL+04AgHpGtC3+Cp0RNJZ86uS/c0PQ0zTWWvjulA7orniO37WaCOMy3IKQORsgSrz9mFOSLKiXhXLPH24riw0ylvAD+cEKRjyUCte56HROVaVnaskc1gY3v+j72lZpC70imf99RkK/G5ztNuq9TTX4NISVLRFjPukMUL2E+VaadgNkT6W4HIXy6wKVIX+SyyL3uaXVfDm0WNW6j/pTH/LBp3XxUQMvQMuAtYjKuW52Y8jGka8MES6EcpBO8LR0IscCxY2VQmFXYcXV7W95ln4+rKIv+WjG+XOWlR/Q+N9YRXl6iuyp+MjkXInAlRx6JEji4vSzsWqapAfFzVeFrt+GK1H1EQaIXF6Zu6xNGHbI0MpPJFFB4K5AGRThk9WBKC1MiAPXb4yWBesGXIJk9qhcUIEhgIDAQGAgPtZcCe8e2dQb0jz+PDvffq7S14O3nF8eFoX3Vu6n5kBqpqZmDFkM6HId8zu6aMPhZ4BQZpgAGIzft+QTdooL8Rl3MjmtlRrGuqXwX3t6q8M78xRmaVfEjmvw04ZlyJTWHo6UOxRgYgn+OFc96VRIXM04ViAwwQ3WuO30fK87pxf1hsoNtTl+f9GbHRjv8D58saQyIsCJHAb1vshHDkiISrkq464if1ILPEwB/mAuUCN7NZlAAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "id": "9d58833e",
   "metadata": {},
   "source": [
    "### Data Normalization and Standardization\n",
    "\n",
    "To train the neuronal network, data normalization and standardization are crucial. \n",
    "\n",
    "Typical RGB images range between 0 and 255 per color channel. The normalization procedure will scale the images to range between 0 and 1. The standardization will be performed with a z-transformation for each channel. The z-transformation scales all data using mean and standard deviation: \n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "The script will calculate the channel-wise mean and standard deviation across the entire sample for subsequent z-transformations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c24cb246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "996d636715a143a5873a91a7116b8812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means per RGB channel = [0.53955701 0.38888616 0.56235658]\n",
      "Standard deviations per RGB channel = [0.21415865 0.2144178  0.16906027]\n"
     ]
    }
   ],
   "source": [
    "# First, we loop across all files to compute sample mean and std per channel  \n",
    "\n",
    "# Create empty lists \n",
    "means = []\n",
    "stds = []\n",
    "\n",
    "for counter, path_to_img in enumerate(tqdm(all_files)):\n",
    "     \n",
    "    # Load the data and normalize by 255 (RGB max)\n",
    "    img = np.asarray(Image.open(path_to_img)) / 255\n",
    "    \n",
    "    # Calculate the image mean and standard deviation, and append them to the predifined lists.\n",
    "    means.append(img.mean(axis = (0,1)))\n",
    "    stds.append(img.std(axis = (0,1)))\n",
    "\n",
    "# Convert lists to numpy arrays and calculate sample mean and standard deviation \n",
    "channel_means = np.array(means).mean(axis = 0)\n",
    "channel_stds = np.array(stds).mean(axis = 0)\n",
    "\n",
    "print('Means per RGB channel = {}'.format(channel_means))\n",
    "print('Standard deviations per RGB channel = {}'.format(channel_stds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7da99829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(img, means, stds):\n",
    "    \"\"\"\n",
    "    Channel-wise z-transformation to standardize imgages within the given sample \n",
    "    \"\"\"\n",
    "    \n",
    "    # Create an empty array similar to the image dataset\n",
    "    img_normalized = np.zeros_like(img)\n",
    "    \n",
    "    # Loop over channels, to perform channel-wise z-transformation using external mean and standard deviations \n",
    "    for i in range(img.shape[-1]):\n",
    "        img_normalized[...,i] = (img[...,i] - means[...,i]) / stds[...,i]\n",
    "\n",
    "    \n",
    "    return img_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eafe41e",
   "metadata": {},
   "source": [
    "This function will be stored in the local functions.py file for future use. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38832bfd",
   "metadata": {},
   "source": [
    "### Preprocessing Loop\n",
    "\n",
    "This loop will go through the folder structure, read the image and label data, perform standardization and normalization, and save image and label data as separate NumPy arrays  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3ed3162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ddca083dad44148a3863466189ca3ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocess_path = Path(\"./preprocessed/\") \n",
    "\n",
    "for counter, path_to_img in enumerate(tqdm(all_files)):\n",
    "    \n",
    "    # Load the image data and normalize by 255 (RGB max)\n",
    "    img = np.asarray(Image.open(path_to_img)).astype(np.float32) / 255\n",
    "    \n",
    "    # Load label data as boolean array\n",
    "    mask = np.asarray(Image.open(change_img_to_label_path(path_to_img))).astype(bool)\n",
    "    \n",
    "    # Standardize per Channel using pre calculated means and stand deviations\n",
    "    img_standardize = standardize(img, channel_means, channel_stds)\n",
    "    \n",
    "    # Define save path based on counter\n",
    "    if counter < train:\n",
    "        current_path = preprocess_path/'train'/str(counter)\n",
    "    else: \n",
    "        current_path = preprocess_path/'val'/str(counter)\n",
    "    \n",
    "    # Define save paths for img and mask data \n",
    "    current_path_img = current_path/'data'\n",
    "    current_path_mask = current_path/'masks'\n",
    "    \n",
    "    # Make paths for img and mask data\n",
    "    current_path_img.mkdir(parents=True, exist_ok=True)\n",
    "    current_path_mask.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save data \n",
    "    np.save(current_path_img/'01.npy', img_standardize)\n",
    "    np.save(current_path_mask/'01.npy', mask)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ba8219",
   "metadata": {},
   "source": [
    "Preprocessing done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f4d456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
